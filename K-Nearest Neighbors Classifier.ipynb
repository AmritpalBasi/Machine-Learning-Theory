{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Classifier\n",
    "**K-Nearest Neighbors (KNN)** is a classification algorithm. The central idea is that data points with similar attributes tend to fall into similar categories.\n",
    "***\n",
    "data provided by Code Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance Between Points - 2D\n",
    "\n",
    "We need to first define what it means for two points to be close together or far apart. For this we can use the **Euclidean Distance** formula. \n",
    "\n",
    "$$\n",
    "d = \\sqrt{(a_1 - b_1)^2 + (a_2 - b_2)^2 + ... + (a_n - b_n)^2}\n",
    "$$\n",
    "\n",
    "In the example below we will be working with Movie Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between star wars and raiders of the lost ark 10.770329614269007\n",
      "The distance between star wars and mean girls 38.897300677553446\n"
     ]
    }
   ],
   "source": [
    "# Defining our distance formula \n",
    "def distance(pt1, pt2):\n",
    "    distance = 0\n",
    "    for i in range(len(pt1)):\n",
    "        distance += (pt1[i] - pt2[i]) ** 2\n",
    "    return distance ** 0.5\n",
    "\n",
    "# Movie data containing length of the movie and the release date\n",
    "star_wars = [125, 1977]\n",
    "raiders = [115, 1981]\n",
    "mean_girls = [97, 2004]\n",
    "\n",
    "print('The distance between star wars and raiders of the lost ark', distance(star_wars, raiders))\n",
    "print('The distance between star wars and mean girls',distance(star_wars, mean_girls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalising the Data\n",
    "\n",
    "The problem is that the distance formula treats all dimensions equally, regardless of their scale. If two movies came out 70 years apart, that should be a pretty big deal. However, right now, thatâ€™s exactly equivalent to two movies that have a difference in budget of 70 dollars. The difference in one year is exactly equal to the difference in one dollar of budget. \n",
    "\n",
    "The solution to this problem is to normalize the data so every value is between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.047619047619047616, 0.8492063492063492, 0.8650793650793651, 0.4523809523809524, 0.5634920634920635, 0.46825396825396826, 0.6666666666666666, 0.5476190476190477, 1.0, 0.36507936507936506, 0.6111111111111112, 0.8333333333333334, 0.42063492063492064, 0.0, 0.8253968253968254, 0.4523809523809524, 0.9523809523809523, 0.5873015873015873, 0.0, 0.6904761904761905]\n"
     ]
    }
   ],
   "source": [
    "# Defining our normalisation function\n",
    "def min_max_normalize(lst):\n",
    "  minimum = min(lst)\n",
    "  maximum = max(lst)\n",
    "  normalised = []\n",
    "  for i in lst:\n",
    "    normalised.append((i - minimum)/(maximum-minimum))\n",
    "  return normalised\n",
    "\n",
    "# Dummy Data of release dates\n",
    "release_dates = [1897, 1998, 2000, 1948, 1962, 1950, 1975, 1960, 2017, 1937, 1968, 1996, \n",
    "1944, 1891, 1995, 1948, 2011, 1965, 1891, 1978]\n",
    "\n",
    "# Testing our function\n",
    "print(min_max_normalize(release_dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the Nearest Neighbors\n",
    "\n",
    "Now the data has been normalised and we know how to find the distance between two points we can begin classifying unkown data. To do this we want to find the k nearest neighbors of an unclassified point. In the example below we will be using k = 5.\n",
    "\n",
    "In order to find the 5 nearest neighbors, we need to compare this new unclassified movie to every other movie in the dataset. We ultimately want to end up with a sorted list of distances (between the unclassified point and movies) and the movie labels associated with those distances.\n",
    "\n",
    "Once that is done we need to find out how many 'good' movies and how many 'bad' movies are in the list of neighbors and use that data in order to classify the point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our classification function\n",
    "\n",
    "def classify(unknown, dataset, labels, k):\n",
    "  distances = []\n",
    "  for i in dataset:\n",
    "    distance_to_point = distance(dataset[i], unknown)\n",
    "    distances.append([distance_to_point, i])\n",
    "    distances.sort()\n",
    "    neighbors = distances[:k]\n",
    "\n",
    "    num_good = []\n",
    "    num_bad = []\n",
    "    for neighbor in neighbors:\n",
    "      i = neighbor[1]\n",
    "      if labels[i] == 0:\n",
    "        num_bad +=1\n",
    "      elif labels[i] == 1:\n",
    "        num_good += 1\n",
    "      \n",
    "      if num_good > num_bad:\n",
    "        return 1\n",
    "      else:\n",
    "        return\n",
    "  return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Importing the module\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Dummy Data\n",
    "training_points = [\n",
    "  [0.5, 0.2, 0.1],\n",
    "  [0.9, 0.7, 0.3],\n",
    "  [0.4, 0.5, 0.7]\n",
    "]\n",
    "\n",
    "training_labels = [0, 1, 1]\n",
    "\n",
    "unknown_points = [\n",
    "  [0.2, 0.1, 0.7],\n",
    "  [0.4, 0.7, 0.6],\n",
    "  [0.5, 0.8, 0.1]\n",
    "]\n",
    "\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors = 3)\n",
    " \n",
    "training_labels = [0, 1, 1]\n",
    "classifier.fit(training_points, training_labels)\n",
    "\n",
    "guesses = classifier.predict(unknown_points)\n",
    "print(guesses)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4de312b0d175b34599d3d826f04a5a17f86de583485ee3ee21acf667e9e0881"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
